{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport os, os.path \nimport numpy \nimport pickle\nfrom glob import glob\n\n\"\"\"Change to the data folder\"\"\"\nnew_path = \"./new_train/new_train\"\n#new_path = r\"C:\\Users\\mnisyu\\Desktop\\CSE151B competition\\cse151b-spring\\\\\"\n#new_path = \"..\"\n\n# number of sequences in each dataset\n# train:205942  val:3200 test: 36272 \n# sequences sampled at 10HZ rate","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Create a dataset class ","metadata":{}},{"cell_type":"code","source":"import pickle\n\nclass ArgoverseDataset(Dataset):\n    \"\"\"Dataset class for Argoverse\"\"\"\n    def __init__(self, data_path: str, transform=None):\n        super(ArgoverseDataset, self).__init__()\n        self.data_path = data_path\n        self.transform = transform\n\n        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n        self.pkl_list.sort()\n        \n    def __len__(self):\n        return len(self.pkl_list)\n\n    def __getitem__(self, idx):\n\n        pkl_path = self.pkl_list[idx]\n        with open(pkl_path, 'rb') as f:\n            data = pickle.load(f)\n            \n        if self.transform:\n            data = self.transform(data)\n\n        return data\n\n\n# intialize a dataset\ntrain_data  = ArgoverseDataset(data_path=\"../input/kaggle-competitions-download-c-cse151bspring/new_train/new_train/\")\ntest_data  = ArgoverseDataset(data_path=\"../input/kaggle-competitions-download-c-cse151bspring/new_val_in/new_val_in/\")","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Create a loader to enable batch processing","metadata":{}},{"cell_type":"markdown","source":"# By Lehan Li","metadata":{}},{"cell_type":"code","source":"import itertools\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nbatch_sz = 4\n\ndef my_collate(batch):\n    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n    inp = [np.dstack([scene['p_in'][:,:,0].reshape(60*19),scene['p_in'][:,:,1].reshape(60*19),scene['v_in'][:,:,0].reshape(60*19),scene['v_in'][:,:,1].reshape(60*19)]).reshape(60*19,4) for scene in batch]\n    \n    indexs = [np.where(scene['agent_id'] == scene['track_id'][:,0].reshape(60))[0][0] for scene in batch]\n    #p_in= [scene['p_in'][index] for (scene,index) in zip(batch, indexs)]\n    #v_in = [scene['v_in'][index] for (scene,index) in zip(batch, indexs)]\n    #inp = [np.concatenate((p[:,0],p[:,1],v[:,0],v[:,1])).reshape(76,1) for(p,v) in zip(p_in,v_in)]\n    \n    p_out = [scene['p_out'][index] for (scene,index) in zip(batch, indexs)]\n    v_out = [scene['v_out'][index] for (scene,index) in zip(batch, indexs)]\n    out = [np.concatenate((p[:,0],p[:,1],v[:,0],v[:,1])) for(p,v) in zip(p_out,v_out)]\n    \n    inp = torch.FloatTensor(inp)\n    out = torch.FloatTensor(out)\n    return [inp, out]\n\ntrain_loader = DataLoader(train_data,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0, drop_last=True)","metadata":{"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"_, (example_datas, labels) = next(enumerate(train_loader))\nexample_datas.size()\n#labels.size()","metadata":{"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"torch.Size([4, 1140, 4])"},"metadata":{}}]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.lstm = torch.nn.LSTM(4, 1, 4, dropout=0.2)\n        self.conv1 = torch.nn.Conv1d(1140, 521, 1)\n        self.conv2 = torch.nn.Conv1d(521, 256, 1)\n        self.conv3 = torch.nn.Conv1d(256, 120, 1)\n\n        self.bn1 = torch.nn.BatchNorm1d(521)\n        self.bn2 = torch.nn.BatchNorm1d(256)\n\n        self.drop = torch.nn.Dropout(0.2)\n    def forward(self, inputs):\n        x = inputs\n        x = self.lstm(x)[0]\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.drop(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.drop(x)\n        x = self.conv3(x)\n        return x.reshape(4,120)","metadata":{"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"net = Net()\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\nfor epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(train_loader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 200 == 199:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 200))\n            running_loss = 0.0\n","metadata":{"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"[1,   200] loss: 1252260.297\n[1,   400] loss: 1607374.644\n[1,   600] loss: 1523639.462\n[1,   800] loss: 2148098.919\n[1,  1000] loss: 2100286.278\n[1,  1200] loss: 1910400.954\n[1,  1400] loss: 1861766.410\n[1,  1600] loss: 1815994.726\n[1,  1800] loss: 1673669.487\n[1,  2000] loss: 1617192.509\n[1,  2200] loss: 1545930.605\n[1,  2400] loss: 1540218.615\n[1,  2600] loss: 1441493.768\n[1,  2800] loss: 1400581.814\n[1,  3000] loss: 1334502.979\n[1,  3200] loss: 1289691.495\n[1,  3400] loss: 1209620.647\n[1,  3600] loss: 1250113.216\n[1,  3800] loss: 1204860.927\n[1,  4000] loss: 1149831.371\n[1,  4200] loss: 1066621.613\n[1,  4400] loss: 1081109.162\n[1,  4600] loss: 1073472.740\n[1,  4800] loss: 969267.841\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-59f2533d3e86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-52-788cfc8bf8ff>\u001b[0m in \u001b[0;36mmy_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n        super().__init__()\n        self.hidden_layer_size = hidden_layer_size\n\n        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n\n        self.linear = nn.Linear(hidden_layer_size, output_size)\n\n        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n                            torch.zeros(1,1,self.hidden_layer_size))\n\n    def forward(self, input_seq):\n        lstm_out, self.hidden_cell = self.lstm(input_seq, self.hidden_cell)\n        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n        return predictions[-1]","metadata":{"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"LSTM = LSTM()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\nfor epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(train_loader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport numpy as np","metadata":{"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n\n    def __init__(self, input_size, hidden_dim, num_layers=1):\n        super(Encoder, self).__init__()\n\n        self.input_size = input_size\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(self.input_size, self.hidden_dim, num_layers=self.num_layers)\n        self.hidden = None\n\n    def init_hidden(self, batch_size):\n        return (torch.zeros(self.num_layers, batch_size, self.hidden_dim),\n                torch.zeros(self.num_layers, batch_size, self.hidden_dim))\n\n    def forward(self, inputs):\n        # Push through RNN layer (the ouput is irrelevant)\n        _, self.hidden = self.lstm(inputs, self.hidden)\n        return self.hidden","metadata":{"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n\n    def __init__(self, hidden_dim, num_layers=1):\n        super(Decoder, self).__init__()\n        # input_size=1 since the output are single values\n        self.lstm = nn.LSTM(1, hidden_dim, num_layers=num_layers)\n        self.out = nn.Linear(hidden_dim, 1)\n\n    def forward(self, outputs, hidden, criterion):\n        batch_size, num_steps = outputs.shape\n        # Create initial start value/token\n        input = torch.tensor([[0.0]] * batch_size, dtype=torch.float)\n        # Convert (batch_size, output_size) to (seq_len, batch_size, output_size)\n        input = input.unsqueeze(0)\n\n        loss = 0\n        for i in range(num_steps):\n            # Push current input through LSTM: (seq_len=1, batch_size, input_size=1)\n            #print(hidden[0].size())\n            output, hidden = self.lstm(input, hidden)\n            #print('here')\n            # Push the output of last step through linear layer; returns (batch_size, 1)\n            output = self.out(output[-1])\n            # Generate input for next step by adding seq_len dimension (see above)\n            input = output.unsqueeze(0)\n            # Compute loss between predicted value and true value\n            loss += criterion(output, outputs[:, i])\n        return loss","metadata":{"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"encoder = Encoder(4, 120)\ndecoder = Decoder(120)\ncriterion = nn.MSELoss()\nencoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\ndecoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\na = 0\nfor epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(train_loader, 0):\n        if (len(data[0]) < 4): \n            break\n        inputs,labels = data\n        inputs = inputs.transpose(1,0)\n        \n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n        \n        #print(inputs.shape[1])\n        encoder.hidden = encoder.init_hidden(inputs.shape[1])\n        #print(encoder.hidden[0].size())\n        # Do forward pass through encoder\n        hidden = encoder(inputs)\n        #print(hidden[0].size())\n        #a = hidden\n        # Do forward pass through decoder (decoder gets hidden state from encoder)\n        loss = decoder(labels, hidden, criterion)\n        # Backpropagation\n        loss.backward()\n        # Update parameters\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 200 == 199:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 200))\n            running_loss = 0.0","metadata":{"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"[1,   200] loss: 279803462.320\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-115-3138ad3fd519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# End of Lehan Li","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 4, 120])"},"metadata":{}}]},{"cell_type":"code","source":"if __name__ == '__main__':\n\n    # 5 is the number of features of your data points\n\n    # Create optimizers for encoder and decoder\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n    criterion = nn.MSELoss()\n\n    # Some toy data: 2 sequences of length 10 with 5 features for each data point\n    inputs = [\n        [\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n        ],\n        [\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n            [0.5, 0.2, 0.3, 0.4, 0.1],\n        ]\n    ]\n\n    inputs = torch.tensor(np.array(inputs), dtype=torch.float)\n    # Convert (batch_size, seq_len, input_size) to (seq_len, batch_size, input_size)\n    inputs = inputs.transpose(1,0)\n    print(inputs.size())\n\n    # 2 sequences (to match the batch size) of length 6 (for the 6h into the future)\n    outputs = [ [0.1, 0.2, 0.3, 0.1, 0.2, 0.3], [0.3, 0.2, 0.1, 0.3, 0.2, 0.1] ]\n    outputs = torch.tensor(np.array(outputs), dtype=torch.float)\n\n    print(outputs.size())\n    #\n    # Do one complete forward & backward pass\n    #\n    # Zero gradients of both optimizers\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n    # Reset hidden state of encoder for current batch\n    encoder.hidden = encoder.init_hidden(inputs.shape[1])\n    # Do forward pass through encoder\n    hidden = encoder(inputs)\n    # Do forward pass through decoder (decoder gets hidden state from encoder)\n    loss = decoder(outputs, hidden, criterion)\n    # Backpropagation\n    loss.backward()\n    # Update parameters\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n    print(\"Loss:\", loss.item())","metadata":{"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"torch.Size([10, 2, 5])\ntorch.Size([2, 6])\nLoss: 0.2605845332145691\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize the batch of sequences","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport random\n\nagent_id = 0\n\ndef show_sample_batch(sample_batch, agent_id):\n    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n    inp, out = sample_batch\n    batch_sz = inp.size(0)\n    agent_sz = inp.size(1)\n    \n    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n    fig.subplots_adjust(hspace = .5, wspace=.001)\n    axs = axs.ravel()   \n    for i in range(batch_sz):\n        axs[i].xaxis.set_ticks([])\n        axs[i].yaxis.set_ticks([])\n        \n        # first two feature dimensions are (x,y) positions\n        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])\n\n        \nfor i_batch, sample_batch in enumerate(val_loader):\n    inp, out = sample_batch\n    \"\"\"TODO:\n      Deep learning model\n      training routine\n    \"\"\"\n    show_sample_batch(sample_batch, agent_id)\n    break","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}