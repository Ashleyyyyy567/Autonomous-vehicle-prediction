{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Author: Yu Cao\n",
    "#\n",
    "#\n",
    "#\n",
    "# 2-layered neural network for autonomous car trajectory predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "import itertools\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = \"./new_train/new_train\"\n",
    "val_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    inp = []\n",
    "    for scene in batch:\n",
    "        a = []\n",
    "        agent_id = scene['agent_id']\n",
    "        agent_idx = np.where(scene['track_id'] == agent_id)[0][0]\n",
    "        p_input = scene['p_in'][agent_idx]\n",
    "        inp.append([item for sublist in p_input for item in sublist])\n",
    "    out = []\n",
    "    for scene in batch:\n",
    "        agent_id = scene['agent_id']\n",
    "        agent_idx = np.where(scene['track_id'] == agent_id)[0][0]\n",
    "        p_out = scene['p_out'][agent_idx]\n",
    "        out.append([item for sublist in p_out for item in sublist])\n",
    "    \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    # size: batch size x 38 (linear p_in)\n",
    "    \n",
    "    out = torch.FloatTensor(out)\n",
    "    # size: batch size x 60 (linear p_out)\n",
    "    \n",
    "    return [inp, out]\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in, train_label = next(iter(val_loader))\n",
    "train_in.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hid1 = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.hid2 = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hid1(x))\n",
    "        x = self.hid2(x)             # linear output length 60\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(n_feature=38, n_hidden=100, n_output=60).to(device)\n",
    "# print(net)  # network architecture\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 324.954\n",
      "[1,   100] loss: 321.473\n",
      "[1,   150] loss: 324.601\n",
      "[1,   200] loss: 324.516\n",
      "[1,   250] loss: 325.949\n",
      "[1,   300] loss: 329.020\n",
      "[1,   350] loss: 323.752\n",
      "[1,   400] loss: 323.963\n",
      "[1,   450] loss: 323.248\n",
      "[1,   500] loss: 325.307\n",
      "[1,   550] loss: 319.126\n",
      "[1,   600] loss: 321.780\n",
      "[1,   650] loss: 323.760\n",
      "[2,    50] loss: 324.954\n",
      "[2,   100] loss: 321.473\n",
      "[2,   150] loss: 324.601\n",
      "[2,   200] loss: 324.516\n",
      "[2,   250] loss: 325.949\n",
      "[2,   300] loss: 329.020\n",
      "[2,   350] loss: 323.752\n",
      "[2,   400] loss: 323.963\n",
      "[2,   450] loss: 323.248\n",
      "[2,   500] loss: 325.307\n",
      "[2,   550] loss: 319.126\n",
      "[2,   600] loss: 321.780\n",
      "[2,   650] loss: 323.760\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple time\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        #print(outputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 200 mini-batches\n",
    "            #print(outputs[0])\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 50))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'model.pth' # save model\n",
    "torch.save(net, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hid1): Linear(in_features=38, out_features=100, bias=True)\n",
       "  (hid2): Linear(in_features=100, out_features=60, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input tensors for test data\n",
    "def test_collate(batch):\n",
    "    inp = []\n",
    "    for scene in batch:\n",
    "        a = []\n",
    "        agent_id = scene['agent_id']\n",
    "        agent_idx = np.where(scene['track_id'] == agent_id)[0][0]\n",
    "        p_input = scene['p_in'][agent_idx]\n",
    "        inp.append([item for sublist in p_input for item in sublist])\n",
    "    \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset  = ArgoverseDataset(data_path=\"./new_val_in/new_val_in\")\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=0)\n",
    "test_in = next(iter(test_loader))\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    data = data.to(device)\n",
    "    pred = net(data)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output tensors to list of lists\n",
    "predictions_lst = []\n",
    "for batch in predictions:\n",
    "    for scene in batch:\n",
    "        predictions_lst.append(scene.tolist())\n",
    "scene_id = submission['ID']\n",
    "scene_id = scene_id.tolist()\n",
    "for i in range(len(predictions_lst)):\n",
    "    predictions_lst[i].insert(0, scene_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "first_submission = pd.DataFrame(predictions_lst, columns = submission.columns)\n",
    "first_submission.to_csv('fc_submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code for report q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = np.random.randint(0,687,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "randpredictions = []\n",
    "truth = []\n",
    "for i, data in enumerate(val_loader, 0):\n",
    "    if i not in sam:\n",
    "        continue\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    pred = net(inputs)\n",
    "    randpredictions.append(pred)\n",
    "    truth.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output tensors to list of lists\n",
    "randpredictions_lst = []\n",
    "for batch in randpredictions:\n",
    "    for scene in batch:\n",
    "        randpredictions_lst.append(scene.tolist())\n",
    "scene_id = submission['ID']\n",
    "scene_id = scene_id.tolist()\n",
    "for i in range(len(randpredictions_lst)):\n",
    "    randpredictions_lst[i].insert(0, scene_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "rand_submission = pd.DataFrame(randpredictions_lst, columns = submission.columns)\n",
    "rand_submission.to_csv('rand_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output tensors to list of lists\n",
    "truth_lst = []\n",
    "for batch in truth:\n",
    "    for scene in batch:\n",
    "        truth_lst.append(scene.tolist())\n",
    "scene_id = submission['ID']\n",
    "scene_id = scene_id.tolist()\n",
    "for i in range(len(truth_lst)):\n",
    "    truth_lst[i].insert(0, scene_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "truth_submission = pd.DataFrame(truth_lst, columns = submission.columns)\n",
    "truth_submission.to_csv('truth_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
